{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9824700,"sourceType":"datasetVersion","datasetId":6024711},{"sourceId":12196703,"sourceType":"datasetVersion","datasetId":7682838}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U ultralytics\n!pip install -U ipywidgets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:26:47.127603Z","iopub.execute_input":"2025-06-17T14:26:47.127832Z","iopub.status.idle":"2025-06-17T14:28:33.271125Z","shell.execute_reply.started":"2025-06-17T14:26:47.127806Z","shell.execute_reply":"2025-06-17T14:28:33.270251Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Splitting the dataset:\ntrain ratio: 50%\nval ratio: 25%\ntest ratio: 25%","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Caminho para o dataset já organizado\ndataset_path = '/kaggle/input/chromosome-oriented-bb/dataset'\n\n# Diretório de saída (onde você quer copiar os dados)\noutput_path = '/kaggle/working'\n\n# Conjuntos\nsplits = ['train', 'val', 'test']\n\nfor split in splits:\n    src_img_dir = os.path.join(dataset_path, 'images', split)\n    src_lbl_dir = os.path.join(dataset_path, 'labels', split)\n\n    dst_img_dir = os.path.join(output_path, split, 'images')\n    dst_lbl_dir = os.path.join(output_path, split, 'labels')\n\n    os.makedirs(dst_img_dir, exist_ok=True)\n    os.makedirs(dst_lbl_dir, exist_ok=True)\n\n    for fname in os.listdir(src_img_dir):\n        if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n            continue\n\n        # Copia imagem\n        shutil.copy(os.path.join(src_img_dir, fname),\n                    os.path.join(dst_img_dir, fname))\n\n        # Copia label correspondente (se existir)\n        label_name = os.path.splitext(fname)[0] + '.txt'\n        label_src = os.path.join(src_lbl_dir, label_name)\n\n        if os.path.exists(label_src):\n            shutil.copy(label_src, os.path.join(dst_lbl_dir, label_name))\n        else:\n            print(f'⚠️ Sem label para {fname}')\n\nprint(\"Cópia concluída para /kaggle/working/{train,val,test}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:28:33.272361Z","iopub.execute_input":"2025-06-17T14:28:33.272717Z","iopub.status.idle":"2025-06-17T14:29:11.672049Z","shell.execute_reply.started":"2025-06-17T14:28:33.272654Z","shell.execute_reply":"2025-06-17T14:29:11.671242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nworking_path = '/kaggle/working'\n\ndef count_images(split):\n    images_dir = os.path.join(working_path, split, 'images')\n    return len([f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n\ntrain_count = count_images('train')\nval_count = count_images('val')\ntest_count = count_images('test')\ntotal_count = train_count + val_count + test_count\n\nprint(f\"Total de imagens em /kaggle/working: {total_count}\")\nprint(f\"Imagens de treino: {train_count}\")\nprint(f\"Imagens de validação: {val_count}\")\nprint(f\"Imagens de teste: {test_count}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T14:29:11.673888Z","iopub.execute_input":"2025-06-17T14:29:11.674110Z","iopub.status.idle":"2025-06-17T14:29:11.681730Z","shell.execute_reply.started":"2025-06-17T14:29:11.674092Z","shell.execute_reply":"2025-06-17T14:29:11.680908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndataset_path = '/kaggle/input/chromosome-oriented-bb/dataset'\nsplit = 'test'\nimage_id = '7.png'\n\nif not image_id.endswith('.png'):\n    image_id += '.png'\n\nimage_path = os.path.join(dataset_path, 'images', split, image_id)\nlabel_path = os.path.join(dataset_path, 'labels', split, image_id.replace('.png', '.txt'))\n\nimage = cv2.imread(image_path)\nif image is None:\n    raise FileNotFoundError(f'Imagem não encontrada: {image_path}')\n\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nh, w, _ = image.shape\n\nif os.path.exists(label_path):\n    with open(label_path, 'r') as f:\n        for line in f:\n            parts = line.strip().split()\n            if len(parts) != 9:\n                continue\n\n            cls_id = int(parts[0])\n            coords = list(map(float, parts[1:]))\n\n            # Convertendo para pixels\n            points = []\n            for i in range(0, 8, 2):\n                x = int(coords[i] * w)\n                y = int(coords[i + 1] * h)\n                points.append([x, y])\n\n            points = np.array(points)\n\n            # Desenhar polígono\n            cv2.polylines(image, [points], isClosed=True, color=(255, 0, 0), thickness=2)\n\n            # Texto da classe no primeiro ponto\n            cv2.putText(image, f\"Class {cls_id}\", (points[0][0], points[0][1] - 5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\nelse:\n    print(f'Nenhum label encontrado: {label_path}')\n\nplt.figure(figsize=(8, 8))\nplt.imshow(image)\nplt.axis('off')\nplt.title(f\"{split.upper()} - {image_id}\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:30:36.067807Z","iopub.execute_input":"2025-06-17T14:30:36.068442Z","iopub.status.idle":"2025-06-17T14:30:37.157538Z","shell.execute_reply.started":"2025-06-17T14:30:36.068417Z","shell.execute_reply":"2025-06-17T14:30:37.156466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom ultralytics import YOLO\nfrom torch import nn\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = YOLO('yolo11m-obb.pt')\n\ndevice_ids = [0, 1] \n\nconfig_path = '/kaggle/input/config/config.yaml'\n\nresults = model.train(\n    data=config_path,\n    epochs=200,\n    task='obb',\n    batch=4,\n    imgsz=1080,\n    device=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:12:27.014959Z","iopub.execute_input":"2025-06-17T15:12:27.015714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = model.val(data=config_path, task='obb', split=\"test\")\nprint(metrics.results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:08:27.466368Z","iopub.execute_input":"2025-06-17T15:08:27.466695Z","iopub.status.idle":"2025-06-17T15:08:47.586585Z","shell.execute_reply.started":"2025-06-17T15:08:27.466648Z","shell.execute_reply":"2025-06-17T15:08:47.585728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom ultralytics import YOLO\n\ninput_folder = \"/kaggle/working/test/images\"\noutput_folder = \"/kaggle/working/predictions\"\n\nos.makedirs(output_folder, exist_ok=True)\n\nsupported_formats = (\".jpg\", \".jpeg\", \".png\", \".bmp\")  # Formatos suportados\nimage_files = [f for f in os.listdir(input_folder) if f.lower().endswith(supported_formats)]\n\nfor image_file in image_files:\n    input_path = os.path.join(input_folder, image_file)\n\n    model.predict(\n        source=input_path, \n        save_txt=True,\n        task='obb',\n        conf=0.5,\n        project=output_folder,\n        iou=0.5,\n        name=os.path.splitext(image_file)[0],\n        show_labels=False,\n        device=0\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:08:55.021364Z","iopub.execute_input":"2025-06-17T15:08:55.022206Z","iopub.status.idle":"2025-06-17T15:09:25.868697Z","shell.execute_reply.started":"2025-06-17T15:08:55.022175Z","shell.execute_reply":"2025-06-17T15:09:25.867971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\npredictions_folder = \"/kaggle/working/predictions\"\noutput_folder = \"/kaggle/working/predictions_with_boxes\"\ninput_images_folder = \"/kaggle/working/test/images\"\n\nos.makedirs(output_folder, exist_ok=True)\n\nfor subdir in os.listdir(predictions_folder):\n    subdir_path = os.path.join(predictions_folder, subdir)\n    if not os.path.isdir(subdir_path):\n        continue\n\n    label_path = os.path.join(subdir_path, \"labels\", f\"{subdir}.txt\")\n    image_path = os.path.join(input_images_folder, f\"{subdir}.png\")\n\n    if not os.path.exists(label_path):\n        print(f\"Arquivo de labels ausente para: {subdir}\")\n        continue\n    if not os.path.exists(image_path):\n        print(f\"Imagem original ausente para: {subdir}\")\n        continue\n\n    image = cv2.imread(image_path)\n    height, width, _ = image.shape\n\n    with open(label_path, \"r\") as f:\n        for line in f:\n            parts = line.strip().split()\n            if len(parts) != 9:\n                print(f\"Formato inválido na label {label_path}: {line}\")\n                continue\n\n            cls = int(parts[0])\n            coords = list(map(float, parts[1:]))\n\n            # Converter coordenadas normalizadas para pixels\n            points = []\n            for i in range(0, 8, 2):\n                x = int(coords[i] * width)\n                y = int(coords[i + 1] * height)\n                points.append([x, y])\n\n            points = np.array(points)\n\n            # Desenhar o polígono (caixa orientada)\n            cv2.polylines(image, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n\n            # Opcional: escrever a classe no primeiro ponto\n            cv2.putText(image, f\"Class {cls}\", (points[0][0], points[0][1] - 5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n    # Salvar a imagem anotada\n    output_image_path = os.path.join(output_folder, f\"{subdir}.jpg\")\n    cv2.imwrite(output_image_path, image)\n    print(f\"Imagem anotada salva em: {output_image_path}\")\n\nprint(\"Processamento concluído!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:39:54.599412Z","iopub.execute_input":"2025-06-17T14:39:54.600315Z","iopub.status.idle":"2025-06-17T14:40:15.501022Z","shell.execute_reply.started":"2025-06-17T14:39:54.600290Z","shell.execute_reply":"2025-06-17T14:40:15.500088Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\ndef calculate_obb_iou(box1, box2):\n    poly1 = np.array(box1, dtype=np.float32).reshape((4, 2))\n    poly2 = np.array(box2, dtype=np.float32).reshape((4, 2))\n\n    inter_area, _ = cv2.intersectConvexConvex(poly1, poly2)\n    if inter_area == 0:\n        return 0.0\n\n    area1 = cv2.contourArea(poly1)\n    area2 = cv2.contourArea(poly2)\n    union_area = area1 + area2 - inter_area\n\n    return inter_area / union_area if union_area > 0 else 0\n\nground_truth_folder = \"/kaggle/working/test/labels\"\npredictions_folder = \"/kaggle/working/predictions\"\ninput_images_folder = \"/kaggle/working/test/images\"\noutput_folder = \"/kaggle/working/iou_output\"\n\nos.makedirs(output_folder, exist_ok=True)\n\niou_threshold = 0.5\ntrue_positives = 0\nfalse_positives = 0\nfalse_negatives = 0\n\nfor gt_file in os.listdir(ground_truth_folder):\n    gt_path = os.path.join(ground_truth_folder, gt_file)\n    pred_subfolder = os.path.join(predictions_folder, os.path.splitext(gt_file)[0])\n    pred_path = os.path.join(pred_subfolder, \"labels\", gt_file)\n\n    if not os.path.exists(pred_path):\n        print(f\"Predição ausente para: {gt_file}\")\n        continue\n\n    image_name = os.path.splitext(gt_file)[0]\n    image_path = os.path.join(input_images_folder, image_name + \".png\")\n\n    if not os.path.exists(image_path):\n        print(f\"Imagem ausente: {image_path}\")\n        continue\n\n    image = cv2.imread(image_path)\n    if image is None:\n        print(f\"Erro ao carregar imagem: {image_path}\")\n        continue\n\n    height, width, _ = image.shape\n\n    def parse_box(line):\n        coords = list(map(float, line.strip().split()[1:]))\n        # Normalizar para coordenadas absolutas\n        points = [(coords[i] * width, coords[i + 1] * height) for i in range(0, 8, 2)]\n        return points\n\n    with open(gt_path, \"r\") as f:\n        gt_boxes = [parse_box(line) for line in f]\n\n    with open(pred_path, \"r\") as f:\n        pred_boxes = [parse_box(line) for line in f]\n\n    matched = set()\n    for gt_box in gt_boxes:\n        gt_polygon = np.array(gt_box, dtype=np.int32)\n        detected = False\n        for i, pred_box in enumerate(pred_boxes):\n            if i in matched:\n                continue\n            iou = calculate_obb_iou(gt_box, pred_box)\n            if iou >= iou_threshold:\n                matched.add(i)\n                true_positives += 1\n                cv2.polylines(image, [np.array(pred_box, dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=1)\n                detected = True\n                break\n        if not detected:\n            false_negatives += 1\n            cv2.polylines(image, [gt_polygon], isClosed=True, color=(255, 0, 0), thickness=1)\n\n    for i, pred_box in enumerate(pred_boxes):\n        if i not in matched:\n            false_positives += 1\n            cv2.polylines(image, [np.array(pred_box, dtype=np.int32)], isClosed=True, color=(0, 0, 255), thickness=1)\n\n    output_image_path = os.path.join(output_folder, image_name + \"_output.jpg\")\n    cv2.imwrite(output_image_path, image)\n\nprint(f\"True Positives: {true_positives}\")\nprint(f\"False Positives: {false_positives}\")\nprint(f\"False Negatives: {false_negatives}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:09:42.984836Z","iopub.execute_input":"2025-06-17T15:09:42.985157Z","iopub.status.idle":"2025-06-17T15:09:59.605417Z","shell.execute_reply.started":"2025-06-17T15:09:42.985134Z","shell.execute_reply":"2025-06-17T15:09:59.604594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Pastas que você quer compactar\nfolders_to_zip = ['/kaggle/working/test', '/kaggle/working/iou_output', '/kaggle/working/predictions']\n\n# Caminho para a pasta temporária que vai agrupar todas\ntemp_dir = '/kaggle/working/zip_temp'\n\n# Caminho final do arquivo zip\nzip_path = '/kaggle/working/output.zip'\n\n# Garantir que a pasta temporária esteja limpa\nif os.path.exists(temp_dir):\n    shutil.rmtree(temp_dir)\nos.makedirs(temp_dir)\n\n# Copiar as pastas desejadas para a pasta temporária\nfor folder in folders_to_zip:\n    folder_name = os.path.basename(folder)\n    shutil.copytree(folder, os.path.join(temp_dir, folder_name))\n\n# Compactar a pasta temporária\nshutil.make_archive(zip_path.replace('.zip', ''), 'zip', temp_dir)\n\n# (Opcional) Remover a pasta temporária\nshutil.rmtree(temp_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:59:06.889944Z","iopub.execute_input":"2025-06-17T14:59:06.890703Z","iopub.status.idle":"2025-06-17T14:59:32.078366Z","shell.execute_reply.started":"2025-06-17T14:59:06.890659Z","shell.execute_reply":"2025-06-17T14:59:32.077662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\n# Caminhos\npred_dir = \"/kaggle/working/predictions\"\ngt_dir = \"/kaggle/working/test/labels\"\n\n# Função para calcular IoU\ndef compute_iou(box1, box2):\n    x1_min, y1_min, x1_max, y1_max = box1\n    x2_min, y2_min, x2_max, y2_max = box2\n\n    xi1 = max(x1_min, x2_min)\n    yi1 = max(y1_min, y2_min)\n    xi2 = min(x1_max, x2_max)\n    yi2 = min(y1_max, y2_max)\n\n    inter_area = max((xi2 - xi1), 0) * max((yi2 - yi1), 0)\n    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n    union_area = box1_area + box2_area - inter_area\n\n    if union_area == 0:\n        return 0.0\n    return inter_area / union_area\n\n# Função para ler boxes no seu formato\ndef read_boxes(file_path, img_w=640, img_h=640):\n    with open(file_path, \"r\") as f:\n        lines = f.readlines()\n        if not lines:\n            return []\n        items = list(map(float, lines[0].strip().split()))\n        boxes = []\n        for i in range(1, len(items), 4):\n            if i + 3 < len(items):\n                x_c, y_c, w, h = items[i:i + 4]\n                x_c *= img_w\n                y_c *= img_h\n                w *= img_w\n                h *= img_h\n                x_min = x_c - w / 2\n                y_min = y_c - h / 2\n                x_max = x_c + w / 2\n                y_max = y_c + h / 2\n                boxes.append([x_min, y_min, x_max, y_max])\n        return boxes\n\n# Verificação por imagem\nperfect_matches = 0\ntotal_images = 0\n\nfor img_folder in os.listdir(pred_dir):\n    pred_file = os.path.join(pred_dir, img_folder, \"labels\", f\"{img_folder}.txt\")\n    gt_file = os.path.join(gt_dir, f\"{img_folder}.txt\")\n    \n    if not os.path.exists(pred_file) or not os.path.exists(gt_file):\n        continue\n\n    preds = read_boxes(pred_file)\n    gts = read_boxes(gt_file)\n\n    total_images += 1\n\n    if len(gts) == 0:\n        # Se não há GT, considera como perfeitamente correto se também não houver predição\n        if len(preds) == 0:\n            perfect_matches += 1\n        continue\n\n    if len(preds) == 0:\n        # GT não vazio mas predição vazia → falhou\n        continue\n\n    # Matriz de IoUs (GT x Pred)\n    iou_matrix = np.zeros((len(gts), len(preds)))\n\n    for i, gt in enumerate(gts):\n        for j, pred in enumerate(preds):\n            iou_matrix[i, j] = compute_iou(gt, pred)\n\n    # Matching ótimo (Hungarian)\n    cost_matrix = 1 - iou_matrix  # Menor custo = maior IoU\n    gt_idxs, pred_idxs = linear_sum_assignment(cost_matrix)\n\n    matches = 0\n    for gt_idx, pred_idx in zip(gt_idxs, pred_idxs):\n        if iou_matrix[gt_idx, pred_idx] >= 0.5:\n            matches += 1\n\n    # Checa se todos os GTs foram detectados (não importa se houve falsas predições além disso)\n    if matches == len(gts):\n        perfect_matches += 1\n\nprint(f\"Imagens com 100% de acerto (todas GT detectadas): {perfect_matches}/{total_images}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:01:09.344354Z","iopub.execute_input":"2025-06-17T15:01:09.345059Z","iopub.status.idle":"2025-06-17T15:01:09.371904Z","shell.execute_reply.started":"2025-06-17T15:01:09.345033Z","shell.execute_reply":"2025-06-17T15:01:09.371272Z"}},"outputs":[],"execution_count":null}]}