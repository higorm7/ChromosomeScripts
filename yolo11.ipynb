{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9824700,"sourceType":"datasetVersion","datasetId":6024711},{"sourceId":12070321,"sourceType":"datasetVersion","datasetId":7597784}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U ultralytics\n!pip install -U ipywidgets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T12:52:24.340813Z","iopub.execute_input":"2025-06-05T12:52:24.341043Z","iopub.status.idle":"2025-06-05T12:53:53.033977Z","shell.execute_reply.started":"2025-06-05T12:52:24.340993Z","shell.execute_reply":"2025-06-05T12:53:53.033270Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Splitting the dataset:\ntrain ratio: 50%\nval ratio: 25%\ntest ratio: 25%","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\ndataset_path = '/kaggle/input/chromosome-yolo-dataset/yolo_dataset'\n\noutput_path = '/kaggle/working'\n\nsplits = ['train', 'val', 'test']\n\nfor split in splits:\n    src_img_dir = os.path.join(dataset_path, 'images', split)\n    src_lbl_dir = os.path.join(dataset_path, 'labels', split)\n\n    dst_img_dir = os.path.join(output_path, split, 'images')\n    dst_lbl_dir = os.path.join(output_path, split, 'labels')\n\n    os.makedirs(dst_img_dir, exist_ok=True)\n    os.makedirs(dst_lbl_dir, exist_ok=True)\n\n    for fname in os.listdir(src_img_dir):\n        if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n            continue\n\n        shutil.copy(os.path.join(src_img_dir, fname),\n                    os.path.join(dst_img_dir, fname))\n\n        label_name = os.path.splitext(fname)[0] + '.txt'\n        label_src = os.path.join(src_lbl_dir, label_name)\n\n        if os.path.exists(label_src):\n            shutil.copy(label_src, os.path.join(dst_lbl_dir, label_name))\n        else:\n            print(f'Sem label para {fname}')\n\nprint(\"Cópia concluída para /kaggle/working/{train,val,test}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T12:55:33.261562Z","iopub.execute_input":"2025-06-05T12:55:33.262098Z","iopub.status.idle":"2025-06-05T12:56:10.891215Z","shell.execute_reply.started":"2025-06-05T12:55:33.262074Z","shell.execute_reply":"2025-06-05T12:56:10.890541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nworking_path = '/kaggle/working'\n\ndef count_images(split):\n    images_dir = os.path.join(working_path, split, 'images')\n    return len([f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n\ntrain_count = count_images('train')\nval_count = count_images('val')\ntest_count = count_images('test')\ntotal_count = train_count + val_count + test_count\n\nprint(f\"Total de imagens em /kaggle/working: {total_count}\")\nprint(f\"Imagens de treino: {train_count}\")\nprint(f\"Imagens de validação: {val_count}\")\nprint(f\"Imagens de teste: {test_count}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-06-05T12:57:44.695887Z","iopub.execute_input":"2025-06-05T12:57:44.696387Z","iopub.status.idle":"2025-06-05T12:57:44.702389Z","shell.execute_reply.started":"2025-06-05T12:57:44.696364Z","shell.execute_reply":"2025-06-05T12:57:44.701818Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\n\ndataset_path = '/kaggle/input/chromosome-yolo-dataset/yolo_dataset'\nsplit = 'test'\nimage_id = '7.png'\n\nif not image_id.endswith('.png'):\n    image_id += '.png'\n\nimage_path = os.path.join(dataset_path, 'images', split, image_id)\nlabel_path = os.path.join(dataset_path, 'labels', split, image_id.replace('.png', '.txt'))\n\nimage = cv2.imread(image_path)\nif image is None:\n    raise FileNotFoundError(f'Imagem não encontrada: {image_path}')\n\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nh, w, _ = image.shape\n\nif os.path.exists(label_path):\n    with open(label_path, 'r') as f:\n        for line in f:\n            parts = line.strip().split()\n            if len(parts) != 5:\n                continue\n\n            cls_id, x_center, y_center, bw, bh = map(float, parts)\n\n            # YOLO → pixel\n            x_center *= w\n            y_center *= h\n            bw *= w\n            bh *= h\n\n            x1 = int(x_center - bw / 2)\n            y1 = int(y_center - bh / 2)\n            x2 = int(x_center + bw / 2)\n            y2 = int(y_center + bh / 2)\n\n            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n            cv2.putText(image, f\"Class {int(cls_id)}\", (x1, y1 - 5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\nelse:\n    print(f'Nenhum label encontrado: {label_path}')\n\nplt.figure(figsize=(8, 8))\nplt.imshow(image)\nplt.axis('off')\nplt.title(f\"{split.upper()} - {image_id}\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T12:59:56.126154Z","iopub.execute_input":"2025-06-05T12:59:56.126438Z","iopub.status.idle":"2025-06-05T12:59:56.877258Z","shell.execute_reply.started":"2025-06-05T12:59:56.126412Z","shell.execute_reply":"2025-06-05T12:59:56.876505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom ultralytics import YOLO\nfrom torch import nn\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = YOLO('yolo11m.pt')\n\ndevice_ids = [0, 1] \n\nconfig_path = '/kaggle/input/config/config.yaml'\n\nresults = model.train(\n    data=config_path,\n    epochs=200,\n    batch=16,\n    imgsz=1080,\n    device=device_ids\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:00:21.005392Z","iopub.execute_input":"2025-06-05T13:00:21.005987Z","iopub.status.idle":"2025-06-05T13:02:06.829810Z","shell.execute_reply.started":"2025-06-05T13:00:21.005960Z","shell.execute_reply":"2025-06-05T13:02:06.829123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = model.val(data=config_path, split=\"test\")\nprint(metrics.results_dict)\n\n#metrics = model.val(data=config_path, split=\"train\")\n#print(metrics.results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:02:47.842771Z","iopub.execute_input":"2025-06-05T13:02:47.843399Z","iopub.status.idle":"2025-06-05T13:03:13.297733Z","shell.execute_reply.started":"2025-06-05T13:02:47.843376Z","shell.execute_reply":"2025-06-05T13:03:13.297078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom ultralytics import YOLO\n\ninput_folder = \"/kaggle/working/test/images\"\noutput_folder = \"/kaggle/working/predictions\"\n\nos.makedirs(output_folder, exist_ok=True)\n\nsupported_formats = (\".jpg\", \".jpeg\", \".png\", \".bmp\")  # Formatos suportados\nimage_files = [f for f in os.listdir(input_folder) if f.lower().endswith(supported_formats)]\n\nfor image_file in image_files:\n    input_path = os.path.join(input_folder, image_file)\n\n    model.predict(\n        source=input_path, \n        save_txt=True,\n        conf=0.5,\n        project=output_folder,\n        iou=0.6,\n        name=os.path.splitext(image_file)[0],\n        show_labels=False,\n        device=0\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:03:46.039434Z","iopub.execute_input":"2025-06-05T13:03:46.040533Z","iopub.status.idle":"2025-06-05T13:04:18.202486Z","shell.execute_reply.started":"2025-06-05T13:03:46.040492Z","shell.execute_reply":"2025-06-05T13:04:18.201872Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\n\npredictions_folder = \"/kaggle/working/predictions\"\noutput_folder = \"/kaggle/working/predictions_with_boxes\"\ninput_images_folder = \"/kaggle/working/test/images\"\n\nos.makedirs(output_folder, exist_ok=True)\n\nfor subdir in os.listdir(predictions_folder):\n    subdir_path = os.path.join(predictions_folder, subdir)\n    if not os.path.isdir(subdir_path):\n        continue\n\n    label_path = os.path.join(subdir_path, \"labels\", f\"{subdir}.txt\")\n    image_path = os.path.join(input_images_folder, f\"{subdir}.png\")\n\n    if not os.path.exists(label_path):\n        print(f\"Arquivo de labels ausente para: {subdir}\")\n        continue\n    if not os.path.exists(image_path):\n        print(f\"Imagem original ausente para: {subdir}\")\n        continue\n\n    image = cv2.imread(image_path)\n    height, width, _ = image.shape\n\n    with open(label_path, \"r\") as f:\n        for line in f:\n            # Ler valores no formato [classe, x_centro, y_centro, largura, altura]\n            cls, x_center, y_center, bbox_width, bbox_height = map(float, line.split())\n\n            # Converter coordenadas normalizadas para valores absolutos\n            x1 = int((x_center - bbox_width / 2) * width)\n            y1 = int((y_center - bbox_height / 2) * height)\n            x2 = int((x_center + bbox_width / 2) * width)\n            y2 = int((y_center + bbox_height / 2) * height)\n\n            # Desenhar a bounding box\n            start_point = (x1, y1)\n            end_point = (x2, y2)\n            color = (0, 255, 0)  # Cor da bounding box (verde)\n            thickness = 2\n            image = cv2.rectangle(image, start_point, end_point, color, thickness)\n\n    # Salvar a imagem anotada\n    output_image_path = os.path.join(output_folder, f\"{subdir}.jpg\")\n    cv2.imwrite(output_image_path, image)\n    print(f\"Imagem anotada salva em: {output_image_path}\")\n\nprint(\"Processamento concluído!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:04:18.203736Z","iopub.execute_input":"2025-06-05T13:04:18.203949Z","iopub.status.idle":"2025-06-05T13:04:35.908880Z","shell.execute_reply.started":"2025-06-05T13:04:18.203933Z","shell.execute_reply":"2025-06-05T13:04:35.908179Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Função para calcular o IoU\ndef calculate_iou(box1, box2):\n    x1_min, y1_min, x1_max, y1_max = box1\n    x2_min, y2_min, x2_max, y2_max = box2\n    inter_x_min = max(x1_min, x2_min)\n    inter_y_min = max(y1_min, y2_min)\n    inter_x_max = min(x1_max, x2_max)\n    inter_y_max = min(y1_max, y2_max)\n    inter_width = max(0, inter_x_max - inter_x_min)\n    inter_height = max(0, inter_y_max - inter_y_min)\n    inter_area = inter_width * inter_height\n    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n    union_area = box1_area + box2_area - inter_area\n    return inter_area / union_area if union_area > 0 else 0\n\n# Caminhos para ground truth e predições\nground_truth_folder = \"/kaggle/working/test/labels\"  # Pasta com o ground truth\npredictions_folder = \"/kaggle/working/predictions\"  # Pasta com as predições\ninput_images_folder = \"/kaggle/working/test/images\"  # Onde estão as imagens originais\noutput_folder = \"/kaggle/working/iou_output\"  # Pasta para salvar as imagens com boxes\n\n# Certifique-se de que a pasta de saída existe\nos.makedirs(output_folder, exist_ok=True)\n\n# IoU threshold para considerar uma detecção como correta\niou_threshold = 0.5\n\n# Inicializa contadores\ntrue_positives = 0\nfalse_positives = 0\nfalse_negatives = 0\n\n# Loop pelos arquivos do ground truth\nfor gt_file in os.listdir(ground_truth_folder):\n    gt_path = os.path.join(ground_truth_folder, gt_file)\n    \n    # A predição está dentro de uma subpasta da mesma imagem no diretório predictions\n    pred_subfolder = os.path.join(predictions_folder, os.path.splitext(gt_file)[0])  # Imagem sem extensão\n    pred_path = os.path.join(pred_subfolder, \"labels\", gt_file)\n\n    # Verifica se a predição existe para o ground truth\n    if not os.path.exists(pred_path):\n        print(f\"Predição ausente para: {gt_file}\")\n        continue\n\n    # Verifica se o arquivo de imagem existe e se é um arquivo válido\n    image_name = os.path.splitext(gt_file)[0]  # Remove a extensão do nome da imagem\n    image_path = os.path.join(input_images_folder, image_name + \".png\")  # Tentando com .jpg, ou você pode ajustar para .png, etc.\n    \n    if not os.path.exists(image_path):\n        print(f\"Imagem ausente ou tipo de arquivo incorreto: {image_path}\")\n        continue\n\n    # Lê a imagem original\n    image = cv2.imread(image_path)\n    if image is None:\n        print(f\"Não foi possível carregar a imagem: {image_path}\")\n        continue\n\n    height, width, _ = image.shape\n\n    # Lê os bounding boxes do ground truth\n    with open(gt_path, \"r\") as f:\n        gt_boxes = [\n            list(map(float, line.strip().split()[1:]))  # Ignora a classe\n            for line in f\n        ]\n    \n    # Verifica se as caixas do ground truth estão sendo lidas corretamente\n    if not gt_boxes:\n        print(f\"Sem boxes no arquivo de ground truth: {gt_file}\")\n        continue\n\n    # Lê os bounding boxes das predições\n    with open(pred_path, \"r\") as f:\n        pred_boxes = [\n            list(map(float, line.strip().split()[1:]))  # Ignora a classe\n            for line in f\n        ]\n    \n    # Verifica se as caixas de predição estão sendo lidas corretamente\n    if not pred_boxes:\n        print(f\"Sem boxes no arquivo de predição: {pred_path}\")\n        continue\n\n    # Para cada box no ground truth, verifica se foi detectado\n    matched = set()\n    for gt_box in gt_boxes:\n        gt_x_center, gt_y_center, gt_width, gt_height = gt_box\n        gt_x1 = (gt_x_center - gt_width / 2) * width\n        gt_y1 = (gt_y_center - gt_height / 2) * height\n        gt_x2 = (gt_x_center + gt_width / 2) * width\n        gt_y2 = (gt_y_center + gt_height / 2) * height\n\n        gt_box_abs = [gt_x1, gt_y1, gt_x2, gt_y2]\n\n        # Verifica se as coordenadas estão dentro dos limites da imagem\n        if gt_x1 < 0 or gt_y1 < 0 or gt_x2 > width or gt_y2 > height:\n            print(f\"Coordenadas do GT fora dos limites da imagem: {gt_file}\")\n            continue\n\n        # Desenha a caixa do ground truth somente se não for um verdadeiro positivo\n        start_point = (int(gt_x1), int(gt_y1))\n        end_point = (int(gt_x2), int(gt_y2))\n        color = (255, 0, 0)  # Azul para o ground truth\n        thickness = 1\n\n        # Verifica as predições para esse ground truth\n        detected = False\n        for i, pred_box in enumerate(pred_boxes):\n            if i in matched:\n                continue\n\n            pred_x_center, pred_y_center, pred_width, pred_height = pred_box\n            pred_x1 = (pred_x_center - pred_width / 2) * width\n            pred_y1 = (pred_y_center - pred_height / 2) * height\n            pred_x2 = (pred_x_center + pred_width / 2) * width\n            pred_y2 = (pred_y_center + pred_height / 2) * height\n\n            pred_box_abs = [pred_x1, pred_y1, pred_x2, pred_y2]\n\n            # Verifica se as coordenadas de predição estão dentro da imagem\n            if pred_x1 < 0 or pred_y1 < 0 or pred_x2 > width or pred_y2 > height:\n                print(f\"Coordenadas da predição fora dos limites da imagem: {gt_file}\")\n                # Corrige as coordenadas para ficarem dentro dos limites\n                pred_x1 = max(0, pred_x1)\n                pred_y1 = max(0, pred_y1)\n                pred_x2 = min(width, pred_x2)\n                pred_y2 = min(height, pred_y2)\n\n            # Calcula o IoU\n            iou = calculate_iou(gt_box_abs, pred_box_abs)\n            if iou >= iou_threshold:\n                matched.add(i)\n                true_positives += 1\n\n                # Desenha a caixa da predição correta (True Positive)\n                start_point = (int(pred_x1), int(pred_y1))\n                end_point = (int(pred_x2), int(pred_y2))\n                color = (0, 255, 0)  # Verde para acertos\n                image = cv2.rectangle(image, start_point, end_point, color, thickness)\n                detected = True\n                break\n\n        # Se não foi detectado, desenha a caixa do ground truth\n        if not detected:\n            false_negatives += 1\n            image = cv2.rectangle(image, start_point, end_point, color, thickness)\n\n    # Verifica predições não correspondentes (False Positives)\n    for i, pred_box in enumerate(pred_boxes):\n        if i not in matched:\n            false_positives += 1\n            pred_x_center, pred_y_center, pred_width, pred_height = pred_box\n            pred_x1 = (pred_x_center - pred_width / 2) * width\n            pred_y1 = (pred_y_center - pred_height / 2) * height\n            pred_x2 = (pred_x_center + pred_width / 2) * width\n            pred_y2 = (pred_y_center + pred_height / 2) * height\n\n            # Garantir que as coordenadas de predição estão dentro dos limites da imagem\n            pred_x1 = max(0, pred_x1)\n            pred_y1 = max(0, pred_y1)\n            pred_x2 = min(width, pred_x2)\n            pred_y2 = min(height, pred_y2)\n\n            # Desenha a caixa do False Positive\n            start_point = (int(pred_x1), int(pred_y1))\n            end_point = (int(pred_x2), int(pred_y2))\n            color = (0, 0, 255)  # Vermelho para predições erradas\n            image = cv2.rectangle(image, start_point, end_point, color, thickness)\n\n    # Salva a imagem com as caixas desenhadas\n    output_image_path = os.path.join(output_folder, image_name + \"_output.jpg\")\n    cv2.imwrite(output_image_path, image)\n\n# Imprime estatísticas\nprint(f\"True Positives: {true_positives}\")\nprint(f\"False Positives: {false_positives}\")\nprint(f\"False Negatives: {false_negatives}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:04:35.909992Z","iopub.execute_input":"2025-06-05T13:04:35.910262Z","iopub.status.idle":"2025-06-05T13:04:53.532850Z","shell.execute_reply.started":"2025-06-05T13:04:35.910245Z","shell.execute_reply":"2025-06-05T13:04:53.532228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\nfolders_to_zip = ['/kaggle/working/test', '/kaggle/working/iou_output', '/kaggle/working/predictions']\n\ntemp_dir = '/kaggle/working/zip_temp'\n\n# Caminho final do arquivo zip\nzip_path = '/kaggle/working/output.zip'\n\nif os.path.exists(temp_dir):\n    shutil.rmtree(temp_dir)\nos.makedirs(temp_dir)\n\nfor folder in folders_to_zip:\n    folder_name = os.path.basename(folder)\n    shutil.copytree(folder, os.path.join(temp_dir, folder_name))\n\n# Compactar a pasta temporária\nshutil.make_archive(zip_path.replace('.zip', ''), 'zip', temp_dir)\n\nshutil.rmtree(temp_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:04:58.912090Z","iopub.execute_input":"2025-06-05T13:04:58.912846Z","iopub.status.idle":"2025-06-05T13:05:20.839409Z","shell.execute_reply.started":"2025-06-05T13:04:58.912816Z","shell.execute_reply":"2025-06-05T13:05:20.838804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\n\n# Caminhos\npred_dir = \"/kaggle/working/predictions\"\ngt_dir = \"/kaggle/working/test/labels\" \n\n# Função para calcular IoU\ndef compute_iou(box1, box2):\n    x1_min, y1_min, x1_max, y1_max = box1\n    x2_min, y2_min, x2_max, y2_max = box2\n\n    xi1 = max(x1_min, x2_min)\n    yi1 = max(y1_min, y2_min)\n    xi2 = min(x1_max, x2_max)\n    yi2 = min(y1_max, y2_max)\n\n    inter_area = max((xi2 - xi1), 0) * max((yi2 - yi1), 0)\n    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n    union_area = box1_area + box2_area - inter_area\n\n    if union_area == 0:\n        return 0.0\n    return inter_area / union_area\n\n# Função para converter YOLO para box absoluto\ndef yolo_to_box(line, img_w=640, img_h=640):\n    _, x_c, y_c, w, h = map(float, line.strip().split())\n    x_c *= img_w\n    y_c *= img_h\n    w *= img_w\n    h *= img_h\n    x_min = x_c - w / 2\n    y_min = y_c - h / 2\n    x_max = x_c + w / 2\n    y_max = y_c + h / 2\n    return [x_min, y_min, x_max, y_max]\n\n# Verificação por imagem\nperfect_matches = 0\ntotal_images = 0\n\nfor img_folder in os.listdir(pred_dir):\n    pred_file = os.path.join(pred_dir, img_folder, \"labels\", f\"{img_folder}.txt\")\n    gt_file = os.path.join(gt_dir, f\"{img_folder}.txt\")\n    \n    if not os.path.exists(pred_file) or not os.path.exists(gt_file):\n        continue\n\n    with open(pred_file, \"r\") as f:\n        preds = [yolo_to_box(line) for line in f.readlines()]\n    with open(gt_file, \"r\") as f:\n        gts = [yolo_to_box(line) for line in f.readlines()]\n\n    matched = [False] * len(gts)\n\n    for gt_idx, gt_box in enumerate(gts):\n        for pred_box in preds:\n            iou = compute_iou(gt_box, pred_box)\n            if iou >= 0.5:\n                matched[gt_idx] = True\n                break\n\n    if all(matched):\n        perfect_matches += 1\n    total_images += 1\n\nprint(f\"Imagens com 100% de acerto: {perfect_matches}/{total_images}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:05:20.840697Z","iopub.execute_input":"2025-06-05T13:05:20.841422Z","iopub.status.idle":"2025-06-05T13:05:21.055548Z","shell.execute_reply.started":"2025-06-05T13:05:20.841395Z","shell.execute_reply":"2025-06-05T13:05:21.054910Z"}},"outputs":[],"execution_count":null}]}